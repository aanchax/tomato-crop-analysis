import gradio as gr    #gradio provides an interface for machine learning models to run 
import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

import pathlib

# Specify the path to your local dataset directory
local_data_dir = r'D:\SEM 6\IOT\dataset_new\plantvillage'

# Convert the local directory path to a pathlib.Path object
data_dir = pathlib.Path(local_data_dir)

# Check if the directory exists
if not data_dir.exists():
    print("Error: Directory not found.")
else:
    # Proceed with your data loading code
    # For example, you can iterate over images in the directory like this:
    for image_path in data_dir.glob('*/*.jpg'):  # assuming images are in jpg format
        # Process each image as needed
        print(image_path)
#testing
healthy = list(data_dir.glob('Tomato___healthy/*'))
print(healthy[0])
PIL.Image.open(str(healthy[0]))

img_height,img_width=180,180
batch_size=32
train_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2, #Specifies that 20% of the data will be reserved for validation.
  subset="training",    #indicates that this dataset is for training purposes
  seed=123,
  image_size=(img_height, img_width), #specify the size of image
  batch_size=batch_size)  #sets the batch size for loading images during training

val_ds = tf.keras.preprocessing.image_dataset_from_directory(
  data_dir,
  validation_split=0.2,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for images, labels in train_ds.take(1): #iterating over each batch
  for i in range(9):   #will iterate first 9 images in the batch
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")

num_classes = 10    # 10 different classes

#initializes a seqeuntial model
model = Sequential([
  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)), #rescaling
  layers.Conv2D(16, 3, padding='same', activation='relu'),  #Adds a 2D convolutional layer with 16 filters, each with a 3x3 kernel size. 
  layers.MaxPooling2D(),   #Adds a max-pooling layer. This reduces the spatial dimensions of the input volume.
  layers.Conv2D(32, 3, padding='same', activation='relu'),  #Adds another 2D convolutional layer similar to the previous one but with 32 filters.
  layers.MaxPooling2D(),    #Adds another max-pooling layer.
  layers.Conv2D(64, 3, padding='same', activation='relu'), #Adds another 2D convolutional layer with 64 filters.
  layers.MaxPooling2D(),
  layers.Flatten(),  #transforming it into a 1D array
  layers.Dense(128, activation='relu'),  #Adds a fully connected (dense) layer with 128 units and ReLU activation function.
  layers.Dense(num_classes,activation='softmax') #Adds the output layer with num_classes units (10 in this case) and a softmax activation function. 
])


model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

epochs=10
history = model.fit(
  train_ds,
  validation_data=val_ds,
  epochs=epochs
)


def predict_image(img):
  img_4d=img.reshape(-1,180,180,3)
  prediction=model.predict(img_4d)[0]
  return {class_names[i]: float(prediction[i]) for i in range(10)}

import gradio as gr

image = gr.inputs.Image(shape=(180,180))
label = gr.outputs.Label(num_top_classes=10)

gr.Interface(fn=predict_image, inputs=image, outputs=label,interpretation='default').launch(debug='True')
    
